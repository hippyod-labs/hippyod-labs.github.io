---
liquid: true
# VERY IMPORTANT TO PUT THE ABOVE TAG IN THE FRONT MATTER FOR THE post_url TAG TO WORK

layout: post
title: |-
  Images and Containers for App Devs, Part III: Dockerfiles
subtitle: |-
  A short primer on how to write and use Dockerfiles
description: |-
  Part III in a series of short primers specifically geared towards software developers.  This installment covers the basics of
  how to write and use Dockerfiles, including some basics of what is possible to do when designing your own containers.
author: Evan "Hippy" Slatis
date: 2024-04-02 13:19:03 -0600
categories: post cloud containers
---

include::_posts/snippets/standard-header.adoc[]

== Overview

Dockerfiles are scripts that define how images are built.  They can define the user ID, persistent volumes, what software to install in the image, etc.

{back_to_toc}

== General format and information

Dockerfiles have the following format:

  # This is a comment
  <INSTRUCTION> [arguments]

Leading whitespace is ignored, but whitespace in arguments is not.  By convention, Dockerfile instructions are written in ALL CAPS, but the language
is case insensitive.

=== File naming convention

By convention, Dockerfiles are named "Dockerfile" without an extension.

  podman build .

The build command above will automatically look for a file named "Dockerfile" in the current directory.  To deviate from convention, Podman has the flag `-f` or `--file`, which can take a path or a URL as an argument; e.g.

  podman build -f Dockerfile.my_ext

=== JSON vs freeform text

Instructions have two general forms:

  # JSON array: **you must use double-quotes**
  # executable INSTRUCTIONs refer to this as "exec" style
  <INSTRUCTION> <OPTIONS> ["value1", ..., "valueN"]

  # Free form text
  # executable INSTRUCTIONs refer to this as "shell" style
  <INSTRUCTION> <OPTIONS> value1 ... valueN

{back_to_toc}

=== Squashing image layers

In general, every instruction in a Dockerfile adds a layer to the new image, although only those that actually modify the image filesystem increase the image size.  Layers are cached for faster builds and downloads.

Podman has the `--squash` flag to compress them into a single layer and it's turned on by default, but it is still considered good practice to use as few different instructions in your Dockerfile as possible; e.g. looking at an example <<RUN>> statement that will upgrade everything in the base image, install wget, and then clean the dnf cache to reduce image size:

  # bad practice, creates three new layers
  RUN dnf upgrade -y --no-docs --refresh
  RUN dnf install -y --no-docs wget
  RUN dnf clean all

  # good practice, creates a single layer
  RUN dnf upgrade -y --no-docs --refresh && \
      dnf install -y --no-docs wget && \
      dnf clean all

https://docs.docker.com/reference/cli/docker/image/build/#squash[`docker build --squash` will also work^], but it's considered experimental for the moment, which means the Docker daemon will need to be started with the `--experimental` flag to use it.

On Podman only there is also a `--squash-all` flag that will remove not only all intermediate layers in your current build, but all layers of the base image, too.  The resulting image will be a single layer.

==== Heredoc

We purposefully used the <<RUN>> command to illustrate the point on proper writing of Dockerfiles so we could also take an aside on a recent
improvement to Dockerfiles, heredoc:

  # Same RUN command as above but using heredoc, meaning no line continuation escapes needed
  RUN <<EOF
    set -e # fail the whole Dockerfile if any of the commands below fail
    dnf upgrade -y --no-docs --refresh
    dnf install -y --no-docs wget
    dnf clean all
  EOF

<<COPY and ADD>>  also support heredocs.  Most Dockerfiles you'll review on the internet will look like the first example, because heredoc was introduced only a few years ago for Docker, and only late in 2023 for Podman.  We recommend using heredoc for your Dockerfiles, because it's a cleaner, more readable option.

==== Pros and cons of squash

The pros of removing layers is image size.  This can help pulling large images go faster and minimize utilization of network resources.

On the other hand, Podman only needs to download a layer once, so if you have multiple images that make use of the same base image it can detrimentally hurt performance to use `--squash-all`.  If you have a layer that is shared across a number of images and it's been squashed, Podman cannot take advantage of it.  Lastly, squashing an image build can use up more local drive resources on your build machine.

{back_to_toc}

=== Common Dockerfile Instructions

The following comprises around half of the available https://docs.docker.com/reference/dockerfile/[instructions available in a Dockerfile^].  They are the commands that are most commonly used, and the ones we'll use in the lab below. 

Since this is not a reference document, the instructions are loosely presented in the order they will typically be used in a Dockerfile, and the information given represents only a cursory overview of the instruction to get a developer new to Dockerfiles up to speed and and working quickly. Each instruction section header links to the full and official reference documentation if more in depth information is wanted or required.

{back_to_toc}

==== https://docs.docker.com/reference/dockerfile/#from[FROM^]

  FROM <image>[:<tag>]

Defines the base image of the build.  Usually the first line of every Dockerfile.  If no tag is given, _latest_ is assumed.

  # the following two statements are equivalent
  FROM busybox
  FROM busybox:latest

  # Declaring a specific base image, in this case the Python image built from the alpine image
  FROM python:alpine

{back_to_toc}

==== https://docs.docker.com/reference/dockerfile/#arg[ARG^]

  ARG <name>[=<default value>]

Defines a build time variable.  Variables can be statically assigned a default value or left empty to act as parameters to be passed through the command line when starting a build.  These key/values pairs are only available during the build, and will not be part of the image when the build is completed.  Argument scope is from the line in which is declared in the Dockerfile.

CAUTION: If an argument is defined on the command line but never declared in the Dockerfile, any references to it will be empty.

  # defines a build parameter optionally set on the command line
  # that can be used when the build is executing
  ARG MY_COMMAND_LINE_PARAMETER

  # defines a variable value that can be used when the build is executing
  # defining this variable on the command line will override it
  ARG MY_DOCKERFILE_VARIABLE=someValue

Referencing a previously defined argument is done similar to Shell, `${<arg name>}`.  If you need to pass an argument to running container, assign it to an environment variable using an <<ENV>> statement.

  # Referencing the ARG later in Dockerfile and passing it to the container
  ENV MY_FORMER_COMMAND_LINE_PARAMETER=${MY_COMMAND_LINE_PARAMETER}

===== Using the CLI to pass in argument values

Assigning values on the command line for an argument or arguments:

  podman --build-arg MY_ARG1=my_value1 ... --build-arg MY_ARGn=my_valueN

Or using a properties/env file of arg=value lines:

  podman --build-arg-file argfile.conf

WARNING: *DO NOT USE ARG TO PASS BUILD SECRETS*.  They will be visible with https://docs.podman.io/en/latest/markdown/podman-history.1.html[`podman history`].  If you need access to secrets using `podman build`, you can read   https://docs.docker.com/reference/dockerfile/#run---mounttypesecret[more about it here^].

{back_to_toc}

==== https://docs.docker.com/reference/dockerfile/#env[ENV^]

  ENV <name>=<value>

  # equals sign is optional
  ENV <name> <value>

Defines an environmental variable and value.  This value is available in both <<RUN>> statements during the build, and in the running container.

  # defines the locale of the host in a Linux-based container
  ENV LANG=en_US.UTF-8

Environment variables *ALWAYS* override <<ARG,argument>> values of the same name.

  # The output will be "baz"
  ARG foo=bar
  ENV foo=baz
  ARG foo=something_else
  RUN echo ${foo}

{back_to_toc}

==== https://docs.docker.com/reference/dockerfile/#user[USER^]

  USER <username>

Set the current USER for executing commands during the build and for when the container starts.

  # root user
  USER root

  # user with UID 1001: very standard
  USER 1001

Root typically declared towards the top of the Dockerfile to carry out tasks such as installing software, or changing permissions on directory structures for the image.  At the end, it's a best practice to set the USER running the container to a non-privileged user.

{back_to_toc}

==== https://docs.docker.com/reference/dockerfile/#copy[COPY^] and https://docs.docker.com/reference/dockerfile/#add[ADD^]

Moves files into the image being built.  COPY and ADD are very similar, and they will both move *local* files into the image being built.

They each takes a list of paths, moving a list of n-1 files or directories to the last listed file or directory.  They can be
expressed as either a space delimited list or as a JSON-style array.

  # COPY or ADD appConfig.yaml from the target directory to /app/config.yaml in the image
  ADD ["../target/appConfig.yaml", "/app/config.yaml"]
  COPY ../target/appConfig.yaml /app/config.yaml

  # COPY or ADD the file file1.txt and directory dir1 to the app directory in the image
  ADD file1.txt dir1 /app
  COPY ["file1.txt", "dir1", "/app"]

===== Differences between COPY and ADD

COPY stops at copying local files as it, but ADD as some additional capabilities:

* ADD can copy remote files form URLS
* ADD can pull Git repositories
* ADD will automatically unpack local, compressed tar files

CAUTION:  *Use COPY and avoid ADD*.    Using ADD can have unfortunate side effects.  Use `git pull`, `curl`, or `wget` for fetching remote files, and `bzip2` or `gzip` if you need to decompress anything.

{back_to_toc}

==== https://docs.docker.com/reference/dockerfile/#run[RUN^]

Run a command when building the image.  Can be used to install software, create users, set file permissions, etc.

  # Install wget on an RPM-based Linux image
  RUN dnf install -y --no-docs wget

{back_to_toc}

==== https://docs.docker.com/reference/dockerfile/#expose[EXPOSE^]

EXPOSE is functionally a no-op, but it's widely used to document which ports, if any, are expected to be used the by the app inside the container.  It can document whether they are UDP or TCP, with TCP being the  default if not used.

  # TCP ports
  EXPOSE 8080
  EXPOSE 8080/tcp

  # UDP port
  EXPOSE 8080/udp

{back_to_toc}

==== https://docs.docker.com/reference/dockerfile/#volume[VOLUME^]

Mounts a path managed by Podman *from Podman's storage directory on the host* into the container.

When containers are run, their file systems are ephemeral.  If the container needs to be restarted, any files they were using internally are lost and reset to the state they were using when the container was initially launched.

Volumes, on the other hand, are persistent and can survive a container restart.  Multiple containers on the same host system using the same VOLUME definition can share files this way.  The values can be expressed as either a space delimited list or as a JSON-like array.

  # Mounts the Jenkins jobs directory and pluging.txt from the host into the container
  VOLUME /home/jenkins/jobs /var/lib/jenkins/plugins.txt
  VOLUME ["/home/jenkins/jobs", "/var/lib/jenkins/plugins.txt"]

TIP: link:{% post_url 2024-04-01-primer-images-and-containers-part-ii-podman %}#podman-run[Podman `run`^] also has https://docs.docker.com/storage/bind-mounts/[`--volume` and `--mount`^] flags to define _bind mounts_ that similarly mount directories or files in the container, but the path is absolute on the host, not managed by Podman, and not as performant.  This strategy is preferred if the container storage needs to interact with software not running in a container.

{back_to_toc}

==== ENTRYPOINT and CMD

These instructions are defined as follows:

* *ENTRYPOINT* - defines the executable to start when your container launches.  Defaults to `/bin/sh -c`.
* *CMD* - This (poorly named) instruction is actually the list of arguments to pass to the `ENTRYPOINT`.

From a practical standpoint, when running Podman CMD values can be overridden easily, where the ENTRYPOINT requires a flag.

  # will run the alpine image and echo "howdy" to the command line
  podman run --entrypoint echo alpine howdy

  # will run the alpine image and echo "howdy" without a newline to the command line
  podman run --entrypoint echo alpine -n howdy

In the above examples, the ENTRYPOINT is explicitly overridden by the `--entrypoint` flag, whereas the CMD values are implied by the arguments a the end.

Best practices for developers are to default to using the ENTRYPOINT instructions.  Most application images aren't built to run from the command line.  At a minimum, use ENTRYPOINT to defined the executable that will launch the image, if not the arguments depending on how you configure your deployments.

{back_to_toc}

=== Build vs. container runtimes

When writing Dockerfiles, there are instructions that can affect the current build, instructions that affect the running container, and instructions that affect both simultaneously.

==== Arguments vs Environment variables

Dockerfiles define two sets of variables, which at times can be confusing.  One set of variables are <<ARG, arguments>> that are *only available during runtime*, and the other are <<ENV, environment>> variables that are *only available in a running container*.  Both are key/value pairs.

[#argument-variables]
Arguments can be used as either placeholders of which the value is meant to be passed in from command line, or as traditional variable inside the Dockerfile.  Once the image is built, no trace of these key/value pairs are available.

Environment variables are variables that will be available to a running container as soon as it's started.  A common example that are passed to containers are things like the locale or the home directory of a user or piece of software.  These variables can only be used by the software running in a container launched using the image.

==== RUN vs ENTRYPOINT and CMD

<<RUN>> defines commands that are run inside the image (not container) during the build process.  These command will do things like create and set permissions on files and directories, install software, and other configuration your image might need to be set up.  After the build is completed, all that is left are the results of the commands defined in the RUN instruction(s).

<<ENTRYPOINT and CMD>> define the instructions and command line arguments used to launch a container.  They define what is initially executed when the container is first launched.  In practice, these commands can only access environment variables, but there are tricks in which <<argument-variables,argument variables>> can be passed to these commands which will be demonstrated in the <<Practical Lab (~20 mins), lab below>>.

==== USER and WORKDIR

<<USER>> and <<WORKDIR>> affect both build and container runtimes.  Whenever either is set, build instructions will execute as if by the defined user and/or in the defined working directory.  When the container launches, that last user and working directory defined is used.

{back_to_toc}

===== Container security

It goes without saying that good security practices should always be followed when writing code, and Dockerfiles are no exception.  While your applications may look and feel that they're not running on the host machine when a container is launched, it is important to remember they are running on a host.

WARNING: The OCI runtime container environment is isolated, but *NOT* secure.  Unless needed, always define a unprivileged USER before declaring your <<ENTRYPOINT and CMD, ENTRYPOINT or CMD>>; e.g. `USER 1001`.

{back_to_toc}

==== WORKDIR

  WORKDIR <path>

Set the containers working directory.  WORKDIR may be used multiple times in a Dockerfile.  The initial WORKDIR is whatever was the last value in the <<FROM,base image>>.  If no WORKDIR has ever been set, it's the root directory, `/`.  Relative paths are relative to the current working directory.

  WORKDIR /app
  WORKDIR resources
  RUN pwd

Output of the above with be `/app/resources`.

===== Windows OS



{back_to_toc}

== Practical Lab (~20 mins)

include::_posts/snippets/terminal-tip.adoc[]

The following is a very short lab that will teach you how to build images using Dockerfiles, and run those images as containers.  It will also demonstrate how to externalize your container’s configuration in order to realize the full benefits of container development and “Build once, deploy many”.

{back_to_toc}

=== Building Images

. Clone the Git repository from GitHub:

    $ git clone https://github.com/hippyod/hello-world-container-lab

. Open the Dockerfile
    .. `$ cd hello-world-container-lab`
    .. `$ vim Dockerfile` +

    1 FROM Docker.io/adoptopenjdk/openjdk11:x86_64-ubi-hippyod-labsl-jre-11.0.14.1_1
    2
    3 USER root
    4
    5 ARG ARG_MESSAGE_WELCOME='Hello, World'
    6 ENV MESSAGE_WELCOME=${ARG_MESSAGE_WELCOME}
    7
    8 ARG JAR_FILE=target/*.jar
    9 COPY ${JAR_FILE} app.jar
    10
    11 USER 1001
    12
    13 ENTRYPOINT ["java", "-jar", "/app.jar"]

    [sidebar]
    This Dockerfile has the following features:

    ... The *<code>FROM</code></strong> statement (line 1) defines the base (or parent) image our image will be built from

    ... The <strong><code>USER</code></strong> statements (lines 3 and 11) define which user is running during the build and at execution.  At first, root is running in the build process, and in more complicated Dockerfiles I would need to be root to install any extra software, change file permissions, etc.,  to complete our new image.  At the end of the Dockerfile, I change to the user with UID 1001 so that whenever the image is realized as a container and executes, the user will not be root, and therefore more secure.  I use the UID rather than a username so that the host can recognize which user is running in the container in case the host has enhanced security measures that prevent containers from running as the root user.

    ... The <strong><code>ARG</code></strong> statements (lines 5 and 8) define variables that can be used <em>during the build process only</em>.

    ... The <strong><code>ENV</code></strong> statement (line 6) defines an environment variable and value that can also be used during the build process, but will <em>also be available whenever the image is run as a container</em>.  Note how it obtains its value by referencing the variable defined by the previous <code>ARG</code> statement.

    ... The <strong><code>COPY<sup>1</sup>`* statement (line 9) copies the JAR file created by the Spring Boot Maven build into our image.  For the convenience of users that are running in the Red Hat sandbox, which doesn’t have Java or Maven installed, I have pre-built the JAR file and pushed it to the hello-world-container-lab repo.  There is no need to do a Maven build in this lab.

    ... Finally, the *<code>ENTRYPOINT<sup>2</sup>`* statement defines the command and arguments that should be executed in the container when the container starts up.  If this image ever becomes a base image for a subsequent image definition and a new `ENTRYPOINT` is defined, it will override this one.
    ... Type `:q`  and hit enter to quit the Dockerfile and return to the shell.

. Build the image:

    ```
    $ podman build --squash -t test/hello-world -f Dockerfile
    STEP 1: FROM docker.io/adoptopenjdk/openjdk11:x86_64-ubi-hippyod-labsl-jre-11.0.14.1_1
    Getting image source signatures
    Copying blob d46336f50433 done
    Copying blob be961ec68663 done
    \...
    STEP 7/8: USER 1001
    STEP 8/8: ENTRYPOINT ["java", "-jar", "/app.jar"]
    COMMIT test/hello-world
    \...
    Successfully tagged localhost/test/hello-world:latest
    5482c3b153c44ea8502552c6bd7ca285a69070d037156b6627f53293d6b05fd7
    ```

    Besides building the image:

    .. The `--squash` flag will reduce image size by making sure only one layer is added to the base image when the image build completes.  Excess layers will inflate the size of the resulting image.  *<code>FROM</code></strong>,<strong> <code>RUN</code></strong>, and <strong><code>COPY/ADD</code></strong> statements add layers, and best practices are to concatenate these statements when possible; e.g.

    ```
    RUN dnf -y --refresh update && \
        dnf install -y --nodocs podman skopeo buildah && \
        dnf clean all
    ```

    The above `RUN` statement will not only run each statement to create only a single layer, but will also fail the build should any one of them fail.

    .. The `-t` flag is for naming the image.  Because I did not explicitly define a tag for our name (e.g. `test/hello-world:1.0`), our image will be tagged as `latest` by default.  I also did not define a registry (e.g. `quay.io/test/hello-world`), so our default registry will be `localhost`.
    .. The `-f` flag is for explicitly declaring the Dockerfile to be built.
    .. When running the build, Podman will track the downloading of “blobs”.  These are the image layers your image will be built upon, they are initially pulled from the remote registry, and they will be cached locally to speed up future builds.

    ```
    Copying blob d46336f50433 done
    Copying blob be961ec68663 done
    ...
    Copying blob 744c86b54390 skipped: already exists
    Copying blob 1323ffbff4dd skipped: already exists
    ```

. When the build completes, list the image to confirm it was successfully built:

    ```
    $ podman images
    REPOSITORY                   TAG                                 IMAGE ID      CREATED        SIZE
    localhost/test/hello-world        latest                              140c09fc9d1d  7 seconds ago  454 MB
    docker.io/adoptopenjdk/openjdk11  x86_64-ubi-hippyod-labsl-jre-11.0.14.1_1  5b0423ba7bec  22 hours ago   445 MB

    ```

{back_to_toc}

=== Running Containers

. Run the image

    $ podman run test/hello-world
      .   ____          _            __ _ _
     /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
    ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
     \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
      '  |____| .__|_| |_|_| |_\__, | / / / /
     =========|_|==============|___/=/_/_/_/
     :: Spring Boot ::                (v2.5.4)
    ...
    GREETING: Hello, world
    GREETING: Hello, world

    The output will continue printing “Hello, world” every three seconds until you exit:

    ```
    crtl-c
    ```

. The Spring Boot application running inside our container requires Java in order to run, which is why I chose the base image.  If you’re running in the Red Hat sandbox environment for the lab, we can prove that Java is only installed in the container, and not on the host:

    ```
    $ java -version
    -bash: java: command not found...

    ```

{back_to_toc}

=== Externalize your configuration

We now have our image built and I demonstrated it running with the welcome message I defined in the Dockerfile, but what happens when I want our “Hello, world” message to be different for each environment I deploy the image to, whether because the environment is for a different phase of development or for a different locale?  If I change the value in the Dockerfile, we’ll be required to build a new image to see the message, which breaks one of the most fundamental benefits of containers: “Build *once*, deploy many”, so how do I make my image truly portable so it can be deployed wherever I need it?  The answer lies in externalizing the configuration.

. Run the image with a new, external welcome message:
```
$ podman run -e 'MESSAGE_WELCOME=Hello, world DIT' test/hello-world
  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::                (v2.5.4)

...
GREETING: Hello, world DIT
GREETING: Hello, world DIT
crtl-c
```
```
$ podman run -e 'MESSAGE_WELCOME=Hola Mundo' test/hello-world
  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::                (v2.5.4)

...
GREETING: Hola Mundo
GREETING: Hola Mundo
crtl-c
```

    The `-e` flag defines an environment variable and value to *_inject_* into the container at startup.  As you can see, even if the variable was built into the original image (the `ENV MESSAGE_WELCOME=${ARG_MESSAGE_WELCOME}` statement in your Dockerfile) , it will be overridden.  In this manner, you’ve now externalized data that needed to change based on where it was to be deployed (e.g. in a DIT environment or for Spanish speakers), and thus made your images portable.

. Run the image with a new, external welcome message, but this time the message will be defined in a file:

    ```
    $ echo 'Hello, world from a file' > greetings.txt
    $ podman run -v "$(pwd):/mnt/data:Z" \
        -e 'MESSAGE_FILE=/mnt/data/greetings.txt' test/hello-world
      .   ____          _            __ _ _
     /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
    ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
     \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
      '  |____| .__|_| |_|_| |_\__, | / / / /
     =========|_|==============|___/=/_/_/_/
     :: Spring Boot ::                (v2.5.4)

    ...
    GREETING: Hello, world from a file
    GREETING: Hello, world from a file
    crtl-c
    ```

    The `-e` flag in this case defines a path to the file at /mnt/data/greetings.txt that was mounted from the host's local file system with the `-v` flag at `$(pwd)/greetings.txt` (`pwd` is a bash utility that outputs the absolute path of the current directory, which in your case should be the hello-world-container-lab).  In this manner, you’ve now externalized data that needed to change based on where it was to be deployed, but this time your data was defined in an external file you mounted into the container.  Environment variable settings are OK for a limited number of settings, but when you have a number of settings to apply a file is a more efficient way of injecting the values into your containers.

    *NOTE:* the `:Z` flag at the end of the volume definition above is for systems using [SELinux](https://www.redhat.com/en/topics/linux/what-is-selinux).  SELinux manages security on many Linux distributions, and the flag allows the container access to the directory.  Without the flag, SELinux would prevent the reading of the file, and an exception would be thrown in the container.  Try running the command above again after removing the `:Z` to see a demonstration.

This concludes the lab.

{back_to_toc}

== Developing for Containers: Externalize the Configuration

{back_to_toc}

=== Coding for “Build once, deploy many”

Immutable containers running in different environments that don’t have to worry about differences in the hardware or software that is required to support your particular software project is how “Build once, deploy many” works.  This principle makes software development, debugging, deployment, and ongoing maintenance much, much faster and easier.  It also isn’t perfect, and some minor changes have to be made to how you code in order to make your container truly portable.

The most important design principle when writing software for containerization is deciding what to externalize.  These decisions are what ultimately make your images *portable* so they can fully realize the *“Build once, deploy many”* paradigm.  Although this may seem difficult, there are some easy to remember factors to consider when deciding whether the configuration data should be injectable into your running container:

* *_Is the data environment specific?_*

    Any data that needs to be configured based on where the container is running, whether the environment is a production, non-production, or development environment.  Data of this sort includes internationalization configuration, datastore information, and which testing profile(s) you want your application to run under.

* *_Is the data release independent?_*

    Data of this sort can run the gamut from feature flags to internationalization files to log levels to feature flags.  Any data you might want or need to change in between releases (i.e. without a build and new deployment).

* *Is the data a secret?*

    Credentials should never be hardcoded or stored in an image.  Credentials typically need to be refreshed on schedules that don't match release schedules, and embedding a secret in an image that will be stored in image registry is a security risk.

Best practice is to choose where your configuration data should best be externalized (i.e. an environment variable or a file), and to only externalize those pieces that meet the above criteria.  If it doesn’t meet the above criteria, it is best to leave it as part of the immutable image.  Following these guidelines will make your images truly portable, and keep your external configuration reasonably sized and manageable.

{back_to_toc}

== Additional reading

[A Brief History of Containers: From the 1970s Till Now^](https://blog.aquasec.com/a-brief-history-of-containers-from-1970s-chroot-to-docker-2016)

[A Practical Introduction to Container Terminology^](https://developers.redhat.com/blog/2018/02/22/container-terminology-practical-introduction)

[Dockerfile Reference^](https://docs.docker.com/engine/reference/builder/)

[Podman vs Docker^](https://www.imaginarycloud.com/blog/podman-vs-docker/=:~:text=Docker%20uses%20a%20daemon%2C%20an,does%20not%20need%20the%20mediator.)

{back_to_toc}

== Summary

There are four specific points to be gained from this document for the application developer new to images and containers:

1. *Images are immutable binaries*

    Images are a means of packaging software for later reuse or deployment.

2. *Containers are isolated processes*

    When they are created, containers are a runtime instantiation of an image.  When containers are started, containers become processes in memory on a host machine, which is much lighter and faster than a virtual machine.  For the most part, developers only need to know the latter, but understanding the former is helpful.

3. *“Build once, deploy many”*

    This principle is what makes container technology so useful..  Images and containers provide consistency in deployments and independence from the host machine, allowing it to be deployed with confidence across many different environments.  Containers are also easily scalable because of this principle..

4. *Externalize the configuration*

    If your image has configuration data that is

* Environment specific
* Release independent
* A secret

    Consider making that data external to the image and containers.  You can inject this data into your running image by injecting an environment variable or by mounting an external file into the container.
