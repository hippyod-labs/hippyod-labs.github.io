---
liquid: true
# VERY IMPORTANT TO PUT THE ABOVE TAG IN THE FRONT MATTER FOR THE post_url TAG TO WORK

layout: post
title: |-
  An Images and Containers Primer for App Devs, Part III: Dockerfiles
subtitle: |-
  How to write and use Dockerfiles
description: |-
  Part III in a series of short primers specifically geared towards software developers.  This installment covers the basics of
  how to write and use Dockerfiles, including some basics of what is possible to do when designing your own containers.
author: Evan "Hippy" Slatis
date: 2024-04-02 13:19:03 -0600
categories: post cloud containers
---

include::_posts/snippets/standard-header.adoc[]

{back_to_toc}

== Overview

Dockerfiles are scripts that define your images and how they are built.  They can define base image, the user ID, persistent volumes, what software to install in the image, and more.

This primer assumes the reader is familiar with the basic concepts behind OCI images and containers and Podman/Docker CLI commands.  If not, we suggest reading link:{% post_url 2024-03-27-primer-images-and-containers-part-i-overview %}[Part I^] of this series to cover the basic concepts behind OCI images and containers and/or link:{% post_url 2024-04-01-primer-images-and-containers-part-ii-podman %}[Part II^] that covers the Podman/Docker CLI.

{back_to_toc}

== General format and information

Dockerfiles have the following format:

  # This is a comment
  <INSTRUCTION> [arguments]

Leading whitespace is ignored, but whitespace in arguments is not.  By convention, Dockerfile instructions are written in ALL CAPS, but the language
is case insensitive.

{back_to_toc}

=== File naming convention

By convention, Dockerfiles are named "Dockerfile" without an extension.

  podman build .

The build command above will automatically look for a file named "Dockerfile" in the current directory.  To deviate from convention, Podman has the flag `-f` or `--file`, which can take a path or a URL as an argument; e.g.

  podman build -f Dockerfile.my_ext

{back_to_toc}

=== JSON vs freeform text

Instructions have two general forms:

* JSON array

+
Executable INSTRUCTIONs refer to this as "exec" style.

  <INSTRUCTION> <OPTIONS> ["value1", ..., "valueN"]

+
WARNING: **You must use double-quotes for values.**

* Free form text

+
Executable INSTRUCTIONs refer to this as "shell" style.

  <INSTRUCTION> <OPTIONS> value1 ... valueN

{back_to_toc}

=== Squashing image layers

Every instruction in a Dockerfile adds a link:{% post_url 2024-03-27-primer-images-and-containers-part-i-overview %}#image-layers[layer^] to an image, although only those that actually modify the image filesystem increase the image size.  Layers are cached for faster builds and downloads.

Podman has the `--squash` flag when building images to compress all new layers into a single layer, and it's turned on by default, but it is still considered good practice to use as few instructions in your Dockerfile as possible; e.g. looking at an example <<RUN>> statement that will upgrade everything in the base image, install wget, and then clean the dnf cache to reduce the final image size:

  # bad practice, creates three new layers
  RUN dnf upgrade -y --no-docs --refresh
  RUN dnf install -y --no-docs wget
  RUN dnf clean all

  # good practice, creates a single layer
  RUN dnf upgrade -y --no-docs --refresh && \
      dnf install -y --no-docs wget && \
      dnf clean all

https://docs.docker.com/reference/cli/docker/image/build/#squash[`docker build --squash` will also work^], but it's considered experimental for the moment, which means the Docker daemon will need to be started with the `--experimental` flag to use it.  Docker's documentation also offers a https://docs.docker.com/reference/cli/docker/image/build/#known-limitations[short discussion^] on some of the limitations of squashing an image build, but since the pros almost always outweigh the cons, it's best to leave the option on.

To compress everything including the base image layers into a single layer Podman also offers a `--squash-all` flag, and the resulting image of a build will be a single layer.  This is not currently available with Docker.

{back_to_toc}

==== Heredoc

Most recently both Podman and Docker have begun to support https://en.wikipedia.org/wiki/Here_document#Unix_shells[heredoc^] in Dockerfiles.  Revisiting the <<RUN>> example above:

  RUN <<EOF
    set -e # fail the whole Dockerfile if any of the commands below fail
    dnf upgrade -y --no-docs --refresh
    dnf install -y --no-docs wget
    dnf clean all
  EOF

<<COPY and ADD>> commands also support heredoc.  Most Dockerfiles you'll review on the internet will look like the previous example and not use heredoc, because heredoc was introduced only a few years ago for Docker, and only late in 2023 for Podman.

TIP:  When possible, use heredoc as a cleaner and more readable option to reduce image size. 

{back_to_toc}

=== Common Dockerfile Instructions

Around half of the available instructions available in a Dockerfile are summarized below.  They are the instructions that are most commonly used, and the ones we'll use in the lab below.  They are roughly presented in the order they'd be used in a typical Dockerfile rather than alphabetically, because the purpose of this primer is to help application developers become productive and not to be a reference document.

TIP: For convenience, each header below links to its instruction's https://docs.docker.com/reference/dockerfile/[official Dockerfile reference documentation^].

{back_to_toc}

[#FROM]
==== https://docs.docker.com/reference/dockerfile/#from[FROM^]

  FROM <image>[:<tag>]

Defines the base image of the build.  Usually the first line of every Dockerfile.  If no tag is given, _latest_ is assumed.  FROM can be parameterized with an <<ARG>> statement, but otherwise FROM must be the first statement in a Dockerfile.

  # the following two statements are equivalent
  FROM busybox
  FROM busybox:latest

  # Use the alpine-based Python image
  FROM python:alpine

  # A parameterized FROM statement
  ARG VERSION_PARAMETER
  FROM python:${VERSION_PARAMETER}

{back_to_toc}

[#ARG]
==== https://docs.docker.com/reference/dockerfile/#arg[ARG^]

  ARG <name>[=<default value>]

Defines a build time variable.  Variables can be assigned a default value or left empty to act as parameters to be passed through the command line when starting a build.  These key/values pairs are only available during the build, and will not be part of the image when the build is completed.  Argument scope is from the line in which it is declared.

CAUTION: Arguments must be declared in the Dockerfile.  If an argument is defined on the command line but never declared in the Dockerfile, any references to it will be empty.

  # defines a build parameter optionally set on the command line
  # that can be used when the build is executing
  ARG MY_COMMAND_LINE_PARAMETER

  # defines a variable value that can be used when the build is executing
  # defining this variable on the command line will override it
  ARG MY_DOCKERFILE_VARIABLE=someValue

Referencing a argument is done similar to Shell, `${<arg name>}`.  If you need to pass an argument to running container, assign it to an environment variable using an <<ENV>> statement.

  # Referencing the ARG later in Dockerfile and passing it to the container
  ENV MY_FORMER_COMMAND_LINE_PARAMETER=${MY_COMMAND_LINE_PARAMETER}

{back_to_toc}

===== Using the CLI to pass in argument values

Use the `--build-arg` or `--build-arg-file` options to pass arguments to the Dockerfile:

  # Assign N number of arguments on the command line
  podman --build-arg MY_ARG1=my_value1 ... --build-arg MY_ARGn=my_valueN

Or using a properties/env file of arg=value lines:

  # read in a list of arguments and their values from a file
  podman --build-arg-file argfile.conf

WARNING: **DO NOT USE ARG TO PASS IN BUILD SECRETS**.  The values will be exposed through https://docs.podman.io/en/latest/markdown/podman-history.1.html[`podman history`].  You can https://docs.docker.com/reference/dockerfile/#run---mounttypesecret[read about passing in secrets to ^].

{back_to_toc}

[#ENV]
==== https://docs.docker.com/reference/dockerfile/#env[ENV^]

  ENV <name>=<value> ...

  # the equals operator is optional
  ENV <name> <value> ...

Defines an environmental variable and value.  

  # defines the locale of the host in a Linux-based container
  ENV LANG=en_US.UTF-8

  # define mutliple key/value pairs; use backslashes if values contain spaces
  ENV FOO=BAR BAZ=value\ with\ spaces

ENV values are available both during the build and in the running container.

  ENV MY_VAR=my_value
  # print MY_VAR during the build
  RUN echo ${MY_VAR}
  #print MY_VAR when the container is run
  ENTRYPOINT ["echo", "${MY_VAR}"] 

Environment variables *ALWAYS* override <<ARG,argument>> values of the same name.

  # The output will be "baz"
  ARG foo=bar
  ENV foo=baz
  ARG foo=something_else
  RUN echo ${foo}

Environment variables also support a limited number of https://docs.docker.com/reference/dockerfile/#environment-replacement[bash parameter expansion^] modifiers.

  # if my_env_variable is not defined, use the value some_default_value
  ${my_env_variable:-some_default_value}

{back_to_toc}

[#USER]
==== https://docs.docker.com/reference/dockerfile/#user[USER^]

  USER <username>

Set the current USER to use in the image for subsequent Dockerile instructions.  The last USER defined will be the UID used to launch a container based on the image.

  # root user
  USER root

  # user with UID 1001: very standard
  USER 1001

Root typically declared towards the top of the Dockerfile to carry out tasks such as installing software, or changing permissions on directory structures for the image.

{back_to_toc}

===== Container security

It goes without saying that good security practices should always be followed when writing code, and Dockerfiles are no exception.  While your applications may look and feel that they're not running on the host machine when a container is launched, it is important to remember they are running on a host.

WARNING: The OCI runtime container environment is isolated, but is **NOT** secure.  Unless otherwise needed, best practice is to declare a unprivileged USER before defining your <<ENTRYPOINT and CMD, ENTRYPOINT>>; e.g. `USER 1001`.

{back_to_toc}

[#VOLUME]
==== https://docs.docker.com/reference/dockerfile/#volume[VOLUME^]

  VOLUME <path>

  VOLUME ["<path>"]

Mounts a path managed by Podman from Podman's storage directory on the host into the container.  Volumes should be defined towards the beginning of the Dockerfile before modifying the image contents.  VOLUME definitions are portable across different operating systems, but are not able to be shared.

When containers are run, their file systems are ephemeral.  If the container needs to be restarted, any files they were using internally are lost and reset to the state they were using when the container was initially launched.

VOLUMEs define persistent volumes that can survive a container restart.

  # Mounts the Jenkins jobs directory and pluging.txt from the host into the container
  VOLUME /home/jenkins/jobs /var/lib/jenkins/plugins.txt
  VOLUME ["/home/jenkins/jobs", "/var/lib/jenkins/plugins.txt"]

===== Advanced volume configuration

More advanced options using volumes such as sharing volumes between containers must be managed vio the Podman CLI in order to maintain Dockerfile portability across platforms.  This information is outside the scope of this primer, but more information can be https://docs.docker.com/storage/volumes/[found here^].

{back_to_toc}

[#COPY and ADD]
==== https://docs.docker.com/reference/dockerfile/#copy[COPY^] and https://docs.docker.com/reference/dockerfile/#add[ADD^]

ADD  <src> ... <dest>
ADD  ["<src>", ... "<dest>"]

COPY  <src> ... <dest>
COPY  ["<src>", ... "<dest>"]

Copies files into the image filesystem.  COPY and ADD are very similar, and they will both move **local** files into the image being built.

They each takes a list of paths, moving a list of n-1 files or directories to the last listed file or directory.

  # COPY or ADD appConfig.yaml from the target directory to /app/config.yaml in the image
  ADD ["../target/appConfig.yaml", "/app/config.yaml"]
  COPY ../target/appConfig.yaml /app/config.yaml

  # COPY or ADD the file file1.txt and directory dir1 to the app directory in the image
  ADD file1.txt dir1 /app
  COPY ["file1.txt", "dir1", "/app"]

{back_to_toc}

===== Differences between COPY and ADD

COPY can only copy local files into images, but ADD as some additional capabilities:

* ADD can copy remote files form URLS
* ADD can pull Git repositories
* ADD will automatically unpack compressed tar files

CAUTION:  **Use COPY and avoid ADD**.  Using ADD can have unpredictable side effects.  Use `git pull`, `curl`, or `wget` for fetching remote files, and utilities like `zip`, `bzip2`, or `gzip` if you need to decompress anything.

{back_to_toc}

[#RUN]
==== https://docs.docker.com/reference/dockerfile/#run[RUN^]

  RUN <command> ...
  RUN ["<command", ...]

**Run defines commands that are run during the build**.  Can be used to install software, create users, set file permissions, etc.

  # Install wget on an RPM-based Linux image
  RUN dnf install -y --no-docs wget

Compare this with <<ENTRYPOINT and CMD>>, which defines commands and arguments that only execute when the container is launched.

{back_to_toc}

[#EXPOSE]
==== https://docs.docker.com/reference/dockerfile/#expose[EXPOSE^]

EXPOSE is functionally a no-op, but it's widely used to document which ports, if any, are expected to be used the by the container.  It can document whether they are UDP or TCP, with TCP being the  default if not used.

  # TCP ports
  EXPOSE 8080
  EXPOSE 8080/tcp

  # UDP port
  EXPOSE 8080/udp

{back_to_toc}

==== WORKDIR

  WORKDIR <path>

Set the containers working directory.  WORKDIR may be used multiple times in a Dockerfile.  The initial WORKDIR is whatever was the last value defined in the <<FROM,base image>>.  If no WORKDIR has ever been set, it's the root directory, `/`.  Relative paths are relative to the current working directory.

  WORKDIR /app
  WORKDIR resources
  RUN pwd

Output of the above with be `/app/resources`.

{back_to_toc}

[#ENTRYPOINT and CMD]
==== ENTRYPOINT and CMD

  CMD <command> <param1> ...
  CMD ["<command>", "<param1>", ...]
  CMD <param1> ...
  CMD ["<param1>, ..."]

  ENTRYPOINT <command>, param1 ...
  ENTRYPOINT ["<command>", "param1", ...]

ENTRYPOINT and CMD define the commands and parameters that run and are used when the container is launched.

These instructions are defined as follows:

* ENTRYPOINT - defines the executable to start when your container launches.  Defaults to `/bin/sh -c`. 

* CMD - The list of arguments to pass to the `ENTRYPOINT`.  Can easily be overridden on the command line.

Since ENTRYPOINT defaults to launching a shell and taking a script as an argument, only defining CMD will work, but it creates unnecessary overhead.

  # passes "echo", "-n", and "howdy" as arguments to the ENTRYPOINT
  podman run alpine echo -n howdy

  # overrides the ENTRYPOINT with "echo" and passes 
  podman run --entrypoint "echo" busybox -n howdy

In the above examples, the ENTRYPOINT is explicitly overridden by the `--entrypoint` flag, whereas the CMD values are implied by the arguments a the end.

TIP: Use ENTRYPOINT to define the executable and required parameters that will run when the container is launched.  Use CMD to list optional and/or default arguments that can be overridden on the command line.

Compare this with <<RUN>>, which defines commands that only execute during the build.

{back_to_toc}

== Practical Lab (~20 mins)

include::_posts/snippets/terminal-tip.adoc[]

The following lab that will teach you how to build images using Dockerfiles, view info on the images, and run those images as containers.  It will also demonstrate scalability, and externalizing configuration from the container to demonstrate the principle of "Build once, deploy many".

{back_to_toc}

=== Building Images

. Clone the Git repository from GitHub:

    $ git clone https://github.com/hippyod/hello-world-container-lab

. Open the Dockerfile
    .. `$ cd hello-world-container-lab`
    .. `$ vim Dockerfile` +

    1 FROM Docker.io/adoptopenjdk/openjdk11:x86_64-ubi-hippyod-labsl-jre-11.0.14.1_1
    2
    3 USER root
    4
    5 ARG ARG_MESSAGE_WELCOME='Hello, World'
    6 ENV MESSAGE_WELCOME=${ARG_MESSAGE_WELCOME}
    7
    8 ARG JAR_FILE=target/*.jar
    9 COPY ${JAR_FILE} app.jar
    10
    11 USER 1001
    12
    13 ENTRYPOINT ["java", "-jar", "/app.jar"]

    [sidebar]
    This Dockerfile has the following features:

    ... The *<code>FROM</code></strong> statement (line 1) defines the base (or parent) image our image will be built from

    ... The <strong><code>USER</code></strong> statements (lines 3 and 11) define which user is running during the build and at execution.  At first, root is running in the build process, and in more complicated Dockerfiles I would need to be root to install any extra software, change file permissions, etc.,  to complete our new image.  At the end of the Dockerfile, I change to the user with UID 1001 so that whenever the image is realized as a container and executes, the user will not be root, and therefore more secure.  I use the UID rather than a username so that the host can recognize which user is running in the container in case the host has enhanced security measures that prevent containers from running as the root user.

    ... The <strong><code>ARG</code></strong> statements (lines 5 and 8) define variables that can be used <em>during the build process only</em>.

    ... The <strong><code>ENV</code></strong> statement (line 6) defines an environment variable and value that can also be used during the build process, but will <em>also be available whenever the image is run as a container</em>.  Note how it obtains its value by referencing the variable defined by the previous <code>ARG</code> statement.

    ... The <strong><code>COPY<sup>1</sup>`* statement (line 9) copies the JAR file created by the Spring Boot Maven build into our image.  For the convenience of users that are running in the Red Hat sandbox, which doesn’t have Java or Maven installed, I have pre-built the JAR file and pushed it to the hello-world-container-lab repo.  There is no need to do a Maven build in this lab.

    ... Finally, the **<code>ENTRYPOINT<sup>2</sup>`** statement defines the command and arguments that should be executed in the container when the container starts up.  If this image ever becomes a base image for a subsequent image definition and a new `ENTRYPOINT` is defined, it will override this one.
    ... Type `:q`  and hit enter to quit the Dockerfile and return to the shell.

. Build the image:

    ```
    $ podman build --squash -t test/hello-world -f Dockerfile
    STEP 1: FROM docker.io/adoptopenjdk/openjdk11:x86_64-ubi-hippyod-labsl-jre-11.0.14.1_1
    Getting image source signatures
    Copying blob d46336f50433 done
    Copying blob be961ec68663 done
    \...
    STEP 7/8: USER 1001
    STEP 8/8: ENTRYPOINT ["java", "-jar", "/app.jar"]
    COMMIT test/hello-world
    \...
    Successfully tagged localhost/test/hello-world:latest
    5482c3b153c44ea8502552c6bd7ca285a69070d037156b6627f53293d6b05fd7
    ```

    Besides building the image:

    .. The `--squash` flag will reduce image size by making sure only one layer is added to the base image when the image build completes.  Excess layers will inflate the size of the resulting image.  *<code>FROM</code></strong>,<strong> <code>RUN</code></strong>, and <strong><code>COPY/ADD</code></strong> statements add layers, and best practices are to concatenate these statements when possible; e.g.

    ```
    RUN dnf -y --refresh update && \
        dnf install -y --nodocs podman skopeo buildah && \
        dnf clean all
    ```

    The above `RUN` statement will not only run each statement to create only a single layer, but will also fail the build should any one of them fail.

    .. The `-t` flag is for naming the image.  Because I did not explicitly define a tag for our name (e.g. `test/hello-world:1.0`), our image will be tagged as `latest` by default.  I also did not define a registry (e.g. `quay.io/test/hello-world`), so our default registry will be `localhost`.
    .. The `-f` flag is for explicitly declaring the Dockerfile to be built.
    .. When running the build, Podman will track the downloading of “blobs”.  These are the image layers your image will be built upon, they are initially pulled from the remote registry, and they will be cached locally to speed up future builds.

    ```
    Copying blob d46336f50433 done
    Copying blob be961ec68663 done
    ...
    Copying blob 744c86b54390 skipped: already exists
    Copying blob 1323ffbff4dd skipped: already exists
    ```

. When the build completes, list the image to confirm it was successfully built:

    ```
    $ podman images
    REPOSITORY                   TAG                                 IMAGE ID      CREATED        SIZE
    localhost/test/hello-world        latest                              140c09fc9d1d  7 seconds ago  454 MB
    docker.io/adoptopenjdk/openjdk11  x86_64-ubi-hippyod-labsl-jre-11.0.14.1_1  5b0423ba7bec  22 hours ago   445 MB

    ```

{back_to_toc}

=== Running Containers

. Run the image

    $ podman run test/hello-world
      .   ____          _            __ _ _
     /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
    ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
     \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
      '  |____| .__|_| |_|_| |_\__, | / / / /
     =========|_|==============|___/=/_/_/_/
     :: Spring Boot ::                (v2.5.4)
    ...
    GREETING: Hello, world
    GREETING: Hello, world

    The output will continue printing “Hello, world” every three seconds until you exit:

    ```
    crtl-c
    ```

. The Spring Boot application running inside our container requires Java in order to run, which is why I chose the base image.  If you’re running in the Red Hat sandbox environment for the lab, we can prove that Java is only installed in the container, and not on the host:

    ```
    $ java -version
    -bash: java: command not found...

    ```

{back_to_toc}

=== Externalize your configuration

We now have our image built and I demonstrated it running with the welcome message I defined in the Dockerfile, but what happens when I want our “Hello, world” message to be different for each environment I deploy the image to, whether because the environment is for a different phase of development or for a different locale?  If I change the value in the Dockerfile, we’ll be required to build a new image to see the message, which breaks one of the most fundamental benefits of containers: “Build *once*, deploy many”, so how do I make my image truly portable so it can be deployed wherever I need it?  The answer lies in externalizing the configuration.

. Run the image with a new, external welcome message:
```
$ podman run -e 'MESSAGE_WELCOME=Hello, world DIT' test/hello-world
  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::                (v2.5.4)

...
GREETING: Hello, world DIT
GREETING: Hello, world DIT
crtl-c
```
```
$ podman run -e 'MESSAGE_WELCOME=Hola Mundo' test/hello-world
  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/
 :: Spring Boot ::                (v2.5.4)

...
GREETING: Hola Mundo
GREETING: Hola Mundo
crtl-c
```

    The `-e` flag defines an environment variable and value to *_inject_* into the container at startup.  As you can see, even if the variable was built into the original image (the `ENV MESSAGE_WELCOME=${ARG_MESSAGE_WELCOME}` statement in your Dockerfile) , it will be overridden.  In this manner, you’ve now externalized data that needed to change based on where it was to be deployed (e.g. in a DIT environment or for Spanish speakers), and thus made your images portable.

. Run the image with a new, external welcome message, but this time the message will be defined in a file:

    ```
    $ echo 'Hello, world from a file' > greetings.txt
    $ podman run -v "$(pwd):/mnt/data:Z" \
        -e 'MESSAGE_FILE=/mnt/data/greetings.txt' test/hello-world
      .   ____          _            __ _ _
     /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
    ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
     \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
      '  |____| .__|_| |_|_| |_\__, | / / / /
     =========|_|==============|___/=/_/_/_/
     :: Spring Boot ::                (v2.5.4)

    ...
    GREETING: Hello, world from a file
    GREETING: Hello, world from a file
    crtl-c
    ```

    The `-e` flag in this case defines a path to the file at /mnt/data/greetings.txt that was mounted from the host's local file system with the `-v` flag at `$(pwd)/greetings.txt` (`pwd` is a bash utility that outputs the absolute path of the current directory, which in your case should be the hello-world-container-lab).  In this manner, you’ve now externalized data that needed to change based on where it was to be deployed, but this time your data was defined in an external file you mounted into the container.  Environment variable settings are OK for a limited number of settings, but when you have a number of settings to apply a file is a more efficient way of injecting the values into your containers.

    *NOTE:* the `:Z` flag at the end of the volume definition above is for systems using [SELinux](https://www.redhat.com/en/topics/linux/what-is-selinux).  SELinux manages security on many Linux distributions, and the flag allows the container access to the directory.  Without the flag, SELinux would prevent the reading of the file, and an exception would be thrown in the container.  Try running the command above again after removing the `:Z` to see a demonstration.

This concludes the lab.

{back_to_toc}

== Developing for Containers: Externalize the Configuration

{back_to_toc}

=== Coding for “Build once, deploy many”

Immutable containers running in different environments that don’t have to worry about differences in the hardware or software that is required to support your particular software project is how “Build once, deploy many” works.  This principle makes software development, debugging, deployment, and ongoing maintenance much, much faster and easier.  It also isn’t perfect, and some minor changes have to be made to how you code in order to make your container truly portable.

The most important design principle when writing software for containerization is deciding what to externalize.  These decisions are what ultimately make your images *portable* so they can fully realize the *“Build once, deploy many”* paradigm.  Although this may seem difficult, there are some easy to remember factors to consider when deciding whether the configuration data should be injectable into your running container:

* *_Is the data environment specific?_*

    Any data that needs to be configured based on where the container is running, whether the environment is a production, non-production, or development environment.  Data of this sort includes internationalization configuration, datastore information, and which testing profile(s) you want your application to run under.

* *_Is the data release independent?_*

    Data of this sort can run the gamut from feature flags to internationalization files to log levels to feature flags.  Any data you might want or need to change in between releases (i.e. without a build and new deployment).

* *Is the data a secret?*

    Credentials should never be hardcoded or stored in an image.  Credentials typically need to be refreshed on schedules that don't match release schedules, and embedding a secret in an image that will be stored in image registry is a security risk.

Best practice is to choose where your configuration data should best be externalized (i.e. an environment variable or a file), and to only externalize those pieces that meet the above criteria.  If it doesn’t meet the above criteria, it is best to leave it as part of the immutable image.  Following these guidelines will make your images truly portable, and keep your external configuration reasonably sized and manageable.

{back_to_toc}

== Additional reading

[A Brief History of Containers: From the 1970s Till Now^](https://blog.aquasec.com/a-brief-history-of-containers-from-1970s-chroot-to-docker-2016)

[A Practical Introduction to Container Terminology^](https://developers.redhat.com/blog/2018/02/22/container-terminology-practical-introduction)

[Dockerfile Reference^](https://docs.docker.com/engine/reference/builder/)

[Podman vs Docker^](https://www.imaginarycloud.com/blog/podman-vs-docker/=:~:text=Docker%20uses%20a%20daemon%2C%20an,does%20not%20need%20the%20mediator.)

{back_to_toc}

== Summary

There are four specific points to be gained from this document for the application developer new to images and containers:

1. *Images are immutable binaries*

    Images are a means of packaging software for later reuse or deployment.

2. *Containers are isolated processes*

    When they are created, containers are a runtime instantiation of an image.  When containers are started, containers become processes in memory on a host machine, which is much lighter and faster than a virtual machine.  For the most part, developers only need to know the latter, but understanding the former is helpful.

3. *“Build once, deploy many”*

    This principle is what makes container technology so useful..  Images and containers provide consistency in deployments and independence from the host machine, allowing it to be deployed with confidence across many different environments.  Containers are also easily scalable because of this principle..

4. *Externalize the configuration*

    If your image has configuration data that is

* Environment specific
* Release independent
* A secret

    Consider making that data external to the image and containers.  You can inject this data into your running image by injecting an environment variable or by mounting an external file into the container.
